# Linear-Attention-Mechanism

This repository implementatesLinear-Attention-Mechanism based on PyTorch.

The detailed formula can be seen in the [Linear Attention Mechanism: An Efficient Attention for Semantic Segmentation](https://arxiv.org/ftp/arxiv/papers/2007/2007.14902.pdf).

Feel free to contact me if you need any further information: lironui@whu.edu.cn.

If our code is helpful to you, please cite  
`Li R, Jianlin Su, Duan C and Zheng S. Linear Attention Mechanism: An Efficient Attention for Semantic Segmentation[J]. arXiv preprint arXiv:2007.14902, 2020.`  
`苏剑林. (2020, Jul 04). 《线性Attention的探索：Attention必须有个Softmax吗？ 》[Blog post]. Retrieved from https://spaces.ac.cn/archives/7546`
